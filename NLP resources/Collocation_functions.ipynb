{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import BigramAssocMeasures\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with your filename\n",
    "infile = \"zen.txt\"\n",
    "\n",
    "# Read in the corpus you want to find collocations from\n",
    "with open(infile) as tmpfile:  \n",
    "    data = tmpfile.read()\n",
    "\n",
    "# Clean the data\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "data = data.translate(translator)  # remove punctuation\n",
    "data = \"\".join(i for i in data if ord(i) < 128)  # remove non-ascii characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find collocations for each word\n",
    "def get_collocations(corpus, windowsize=10, numresults=10):\n",
    "    '''This function uses the Natural Language Toolkit to find the top collocations in a corpus.\n",
    "    It takes as an argument a string that contains the corpus you want to\n",
    "    find collocations from. It prints the top collocations it finds.\n",
    "    '''\n",
    "    # convert the corpus (a string) into  a list of words\n",
    "    tokens = word_tokenize(corpus)\n",
    "    # initialize the bigram association measures object to score each collocation\n",
    "    bigram_measures = BigramAssocMeasures()\n",
    "    # initialize the bigram collocation finder object to find and rank collocations\n",
    "    finder = BigramCollocationFinder.from_words(tokens, window_size=windowsize)\n",
    "    # apply a series of filters to narrow down the collocation results\n",
    "    ignored_words = stopwords.words('english')\n",
    "    finder.apply_word_filter(lambda w: len(w) < 2 or w.lower() in ignored_words)\n",
    "    finder.apply_freq_filter(1)\n",
    "    # calculate the top results by T-score\n",
    "    # list of all possible measures: .raw_freq, .pmi, .likelihood_ratio, .chi_sq, .phi_sq, .fisher, .student_t, .mi_like, .poisson_stirling, .jaccard, .dice\n",
    "    results = finder.nbest(bigram_measures.student_t, numresults)\n",
    "    # print the results\n",
    "    print(\"Top \", str(numresults), \" collocations:\")\n",
    "    for k, v in results:\n",
    "        print(str(k), \", \", str(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyword_collocations(corpus, keyword, windowsize=10, numresults=10):\n",
    "    '''This function uses the Natural Language Toolkit to find collocations\n",
    "    for a specific keyword in a corpus. It takes as an argument a string that\n",
    "    contains the corpus you want to find collocations from. It prints the top\n",
    "    collocations it finds for each keyword.\n",
    "    '''\n",
    "    # convert the corpus (a string) into  a list of words\n",
    "    tokens = word_tokenize(corpus)\n",
    "    # initialize the bigram association measures object to score each collocation\n",
    "    bigram_measures = BigramAssocMeasures()\n",
    "    # initialize the bigram collocation finder object to find and rank collocations\n",
    "    finder = BigramCollocationFinder.from_words(tokens, window_size=windowsize)\n",
    "    # initialize a function that will narrow down collocates that don't contain the keyword\n",
    "    keyword_filter = lambda *w: keyword not in w\n",
    "    # apply a series of filters to narrow down the collocation results\n",
    "    ignored_words = stopwords.words('english')\n",
    "    finder.apply_word_filter(lambda w: len(w) < 2 or w.lower() in ignored_words)\n",
    "    finder.apply_freq_filter(1)\n",
    "    finder.apply_ngram_filter(keyword_filter)\n",
    "    # calculate the top results by T-score\n",
    "    # list of all possible measures: .raw_freq, .pmi, .likelihood_ratio, .chi_sq, .phi_sq, .fisher, .student_t, .mi_like, .poisson_stirling, .jaccard, .dice\n",
    "    results = finder.nbest(bigram_measures.student_t, numresults)\n",
    "    # print the results\n",
    "    print(\"Top collocations for \", str(keyword), \":\")\n",
    "    collocations = ''\n",
    "    for k, v in results:\n",
    "        if k != keyword:\n",
    "            collocations += k + ' '\n",
    "        else:\n",
    "            collocations += v + ' '\n",
    "    print(collocations, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top  10  collocations:\n",
      "one ,  way\n",
      "Dutch ,  never\n",
      "good ,  idea\n",
      "guess ,  one\n",
      "idea ,  lets\n",
      "never ,  often\n",
      "never ,  right\n",
      "unless ,  never\n",
      "youre ,  never\n",
      "implementation ,  explain\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Get the top collocations for the entire corpus\n",
    "get_collocations(data)\n",
    "print(' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top collocations for  honking :\n",
      "Namespaces good great lets may idea idea one  \n",
      "\n",
      "Top collocations for  pass :\n",
      "Errors beats Unless ambiguity explicitly face silenced silently practicality purity  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace this with a list of keywords you want to find collocations for\n",
    "words_of_interest = [\"honking\", \"pass\"]\n",
    "\n",
    "# Get the top collocations for each keyword in the list above\n",
    "for word in words_of_interest:\n",
    "    get_keyword_collocations(data, word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
